{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "English, Urdu, Hindi, Chinese, etc. supported language"
      ],
      "metadata": {
        "id": "9wggKPBuskgj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoDkuBaYnFs7",
        "outputId": "ad68975a-a0c8-4554-e5e9-fe0f71ee449e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vosk) (4.67.1)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from vosk) (15.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2025.6.15)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22427 sha256=6a161508b39b2f671f89f8d5ddf3ae96ab11de02de66fbb64102da6a298b3eae\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, vosk\n",
            "Successfully installed srt-3.5.3 vosk-0.3.45\n"
          ]
        }
      ],
      "source": [
        "pip install vosk soundfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zesb8fb_naNF",
        "outputId": "fae493f3-078c-4c8d-8f81-fafdc8b0e5b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-04 09:02:39--  https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41205931 (39M) [application/zip]\n",
            "Saving to: ‚Äòvosk-model-small-en-us-0.15.zip‚Äô\n",
            "\n",
            "vosk-model-small-en 100%[===================>]  39.30M  13.2MB/s    in 3.0s    \n",
            "\n",
            "2025-07-04 09:02:43 (13.2 MB/s) - ‚Äòvosk-model-small-en-us-0.15.zip‚Äô saved [41205931/41205931]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip vosk-model-small-en-us-0.15.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXFs0B_qok-4",
        "outputId": "f1b5ac46-341f-473c-f438-df387de1cec7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  vosk-model-small-en-us-0.15.zip\n",
            "   creating: vosk-model-small-en-us-0.15/\n",
            "   creating: vosk-model-small-en-us-0.15/am/\n",
            "  inflating: vosk-model-small-en-us-0.15/am/final.mdl  \n",
            "   creating: vosk-model-small-en-us-0.15/graph/\n",
            "  inflating: vosk-model-small-en-us-0.15/graph/disambig_tid.int  \n",
            "  inflating: vosk-model-small-en-us-0.15/graph/HCLr.fst  \n",
            "  inflating: vosk-model-small-en-us-0.15/graph/Gr.fst  \n",
            "   creating: vosk-model-small-en-us-0.15/graph/phones/\n",
            "  inflating: vosk-model-small-en-us-0.15/graph/phones/word_boundary.int  \n",
            "   creating: vosk-model-small-en-us-0.15/conf/\n",
            "  inflating: vosk-model-small-en-us-0.15/conf/model.conf  \n",
            "  inflating: vosk-model-small-en-us-0.15/conf/mfcc.conf  \n",
            "   creating: vosk-model-small-en-us-0.15/ivector/\n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/splice.conf  \n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/final.dubm  \n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/global_cmvn.stats  \n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/final.ie  \n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/online_cmvn.conf  \n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/final.mat  \n",
            "  inflating: vosk-model-small-en-us-0.15/README  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import wave\n",
        "import json\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# === Convert MP3 to WAV ===\n",
        "mp3_path = \"/content/audio.mp3\"\n",
        "wav_path = \"/content/audio.wav\"\n",
        "\n",
        "sound = AudioSegment.from_file(mp3_path)\n",
        "sound = sound.set_frame_rate(16000).set_channels(1)\n",
        "sound.export(wav_path, format=\"wav\")\n",
        "\n",
        "# === Vosk Model Path ===\n",
        "MODEL_PATH = \"vosk-model-small-en-us-0.15\"\n",
        "model = Model(MODEL_PATH)\n",
        "\n",
        "# === Load WAV ===\n",
        "wf = wave.open(wav_path, \"rb\")\n",
        "assert wf.getnchannels() == 1\n",
        "assert wf.getsampwidth() == 2\n",
        "assert wf.getframerate() == 16000\n",
        "\n",
        "# === Audio duration ===\n",
        "frames = wf.getnframes()\n",
        "rate = wf.getframerate()\n",
        "duration = frames / float(rate)\n",
        "\n",
        "# === Recognizer ===\n",
        "rec = KaldiRecognizer(model, rate)\n",
        "\n",
        "# === Transcribe + Measure Latency ===\n",
        "start_time = time.time()\n",
        "results = []\n",
        "\n",
        "while True:\n",
        "    data = wf.readframes(4000)\n",
        "    if len(data) == 0:\n",
        "        break\n",
        "    if rec.AcceptWaveform(data):\n",
        "        results.append(json.loads(rec.Result()))\n",
        "results.append(json.loads(rec.FinalResult()))\n",
        "end_time = time.time()\n",
        "\n",
        "# === Output ===\n",
        "transcription = \" \".join([res.get(\"text\", \"\") for res in results])\n",
        "latency = end_time - start_time\n",
        "rtf = latency / duration\n",
        "\n",
        "print(f\"üìù Transcription: {transcription}\")\n",
        "print(f\"üéß Duration: {duration:.2f} seconds\")\n",
        "print(f\"‚è±Ô∏è Latency: {latency:.2f} seconds\")\n",
        "print(f\"‚ö° RTF: {rtf:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auA7VY6XrLWj",
        "outputId": "f80e7836-3d06-4d73-d5f6-658f3ad8ee09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Transcription: to check the latency score of your grope whisper large v three model transcription or any other speech to text model you can measure the in france duration and compare it to the length of the audio to compute the real time factor rt f\n",
            "üéß Duration: 15.24 seconds\n",
            "‚è±Ô∏è Latency: 2.63 seconds\n",
            "‚ö° RTF: 0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wY3JPaiYrllq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}